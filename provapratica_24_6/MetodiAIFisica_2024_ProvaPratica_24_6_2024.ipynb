{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonioHallgass/corso_AI_2025/blob/main/provapratica_24_6/MetodiAIFisica_2024_ProvaPratica_24_6_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova Pratica - Metodi AI per la fisica\n",
        "### 24.6.2024 - AA 2023/24 - Docente: S. Giagu\n",
        "\n",
        "\n",
        "> **Regole:**\n",
        "\n",
        "*   **tempo a disposizione:** 2.5h\n",
        "\n",
        "*   compilare con i vostri dati i campi della cella che segue e poi eseguire la cella verificando che i dati printati corrispondano. L'esecuzione della cella scarica anche i dataset da utilizzare durante la prova;\n",
        "*   risolvere i quesiti/compiti indicati nella cella *Descrizione del compito*. È richiesto di risolvere un problema a scelta tra i problema *A1* e *A2*, e un problema a scelta tra i problemi *B1* e *B2*;\n",
        "*   una volta completato il compito caricare il notebook nel apposito folder sul sito e-learning del corso disponibile al link: <p>\n",
        "[consegna esonero](https://elearning.uniroma1.it/mod/assign/view.php?id=647726)<p>\n",
        "\n",
        "**NOTA 1:** per scaricare localmente il notebook da colab: menù **File->Dowload->Download .ipynb** (non è necessario cambiare il nome del file, il form e-learning associa automaticamnte un folder con il vostro nome e id al file che caricate)\n",
        "<p>\n",
        "\n",
        "**NOTA 2:** una volta caricato e sottomesso il notebook non sono più possibili ulteriori modifiche."
      ],
      "metadata": {
        "id": "bc9160FmJpVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Dati Personali\n",
        "import os\n",
        "\n",
        "Nome = 'Stefano'  #@param {type: \"string\"}\n",
        "Cognome = 'Giagu' #@param {type: \"string\"}\n",
        "NumeroMatricola = 123456780 #@param {type: \"number\"}\n",
        "\n",
        "if NumeroMatricola == 12345678:\n",
        "  print('\\033[1;31m Inserisci il numero di matricola corretto!!!!')\n",
        "else:\n",
        "  print('Download datasets ...')\n",
        "  !wget !wget http://giagu.web.cern.ch/giagu/CERN/dataset_1_AI_24.6.2024.npz\n",
        "  !wget !wget http://giagu.web.cern.ch/giagu/CERN/dataset_2_AI_24.6.2024.npy\n",
        "  !ls\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNPSWZsGV0hy",
        "outputId": "a26cad58-acc2-4faf-d268-dd689234d95a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download datasets ...\n",
            "--2025-06-28 22:38:38--  http://!wget/\n",
            "Resolving !wget (!wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘!wget’\n",
            "--2025-06-28 22:38:38--  http://giagu.web.cern.ch/giagu/CERN/dataset_1_AI_24.6.2024.npz\n",
            "Resolving giagu.web.cern.ch (giagu.web.cern.ch)... 188.185.5.88, 188.185.50.104, 137.138.55.232, ...\n",
            "Connecting to giagu.web.cern.ch (giagu.web.cern.ch)|188.185.5.88|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://giagu.web.cern.ch/giagu/CERN/dataset_1_AI_24.6.2024.npz [following]\n",
            "--2025-06-28 22:38:38--  https://giagu.web.cern.ch/giagu/CERN/dataset_1_AI_24.6.2024.npz\n",
            "Connecting to giagu.web.cern.ch (giagu.web.cern.ch)|188.185.5.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2400256 (2.3M) [application/x-troff-man]\n",
            "Saving to: ‘dataset_1_AI_24.6.2024.npz’\n",
            "\n",
            "dataset_1_AI_24.6.2 100%[===================>]   2.29M  14.9MB/s    in 0.2s    \n",
            "\n",
            "2025-06-28 22:38:38 (14.9 MB/s) - ‘dataset_1_AI_24.6.2024.npz’ saved [2400256/2400256]\n",
            "\n",
            "FINISHED --2025-06-28 22:38:38--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 1 files, 2.3M in 0.2s (14.9 MB/s)\n",
            "--2025-06-28 22:38:38--  http://!wget/\n",
            "Resolving !wget (!wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘!wget’\n",
            "--2025-06-28 22:38:38--  http://giagu.web.cern.ch/giagu/CERN/dataset_2_AI_24.6.2024.npy\n",
            "Resolving giagu.web.cern.ch (giagu.web.cern.ch)... 188.185.5.88, 188.185.50.104, 137.138.55.232, ...\n",
            "Connecting to giagu.web.cern.ch (giagu.web.cern.ch)|188.185.5.88|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://giagu.web.cern.ch/giagu/CERN/dataset_2_AI_24.6.2024.npy [following]\n",
            "--2025-06-28 22:38:38--  https://giagu.web.cern.ch/giagu/CERN/dataset_2_AI_24.6.2024.npy\n",
            "Connecting to giagu.web.cern.ch (giagu.web.cern.ch)|188.185.5.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6553680 (6.2M) [application/x-troff-man]\n",
            "Saving to: ‘dataset_2_AI_24.6.2024.npy’\n",
            "\n",
            "dataset_2_AI_24.6.2 100%[===================>]   6.25M  33.5MB/s    in 0.2s    \n",
            "\n",
            "2025-06-28 22:38:39 (33.5 MB/s) - ‘dataset_2_AI_24.6.2024.npy’ saved [6553680/6553680]\n",
            "\n",
            "FINISHED --2025-06-28 22:38:39--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 1 files, 6.2M in 0.2s (33.5 MB/s)\n",
            "dataset_1_AI_24.6.2024.npz  dataset_2_AI_24.6.2024.npy\tsample_data\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrizione del compito:\n",
        "\n",
        "Svolgere uno tra i due problemi A1 e A2, e uno tra i due problemi B1 e B2.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Problema A1**\n",
        "\n",
        "Viene fornito il dataset in formato numpy compresso: *dataset_1_AI_24.6.2024.npz*, contenente 10000 esempi di eventi descritti da vettori di 30 feature ciascuno (vettore $X$ di shape $(10000,30)$.\n",
        "\n",
        "Per leggere il dataset utilizzare l'esempio di codice:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "f1 = np.load('dataset_1_AI_24.6.2024.npz')\n",
        "X = f1['X']\n",
        "```\n",
        "\n",
        "1. (A1.1): usare l'algoritmo *k-means* per clusterizzare il dataset;\n",
        "2. (A1.2): stimare il numero di cluster utilizzando una tecnica opportuna;\n",
        "3. (A1.3): graficare i risultati ottenuti in un plot bidimensionale colorando ciascun punto in accordo all'indice di cluster fornito da *k-means*;\n",
        "4. (A1.4): applicare un algoritmo di clustering basato su GMM, con numero di cluster ottenuto dal punto A1.2, e stimare la distanza che gli eventi definiti dai feature vectors *A* e *B* hanno dal cluster del GMM che gli è più vicino:\n",
        "\n",
        "\n",
        "> ```\n",
        "A =  np.array([[-5.36505473,  2.07195568,  4.91825063, -4.11366628, -1.42774354,\n",
        "         0.1108879 ,  1.12768349, -3.71341838,  6.30737198,  1.84406497,\n",
        "         3.69745021,  0.66683686,  2.51573212, -3.06422791, -3.05325371,\n",
        "        -3.17967819, -1.0235818 , -0.05819968,  1.52060631, -1.48816709,\n",
        "         1.58701788, -2.89491225,  1.3980812 ,  4.35015951,  0.11112597,\n",
        "        -2.88989763, -1.42208498, -2.21855776,  3.03341608,  3.81970948]])\n",
        "> B = np.array([[-2.64458179,  1.95884469,  2.99352898, -0.2119196 , -0.60619392,\n",
        "         1.98684426, -1.48225564, -4.36632599,  3.68098531, -0.0859702 ,\n",
        "         1.45377991, -1.98137052,  4.02635899, -1.00188601, -1.55315421,\n",
        "        -3.26681447, -3.9642281 ,  1.47756927,  2.24695055, -3.54575546,\n",
        "        -0.51456593, -1.78531078,  0.02494651,  0.68843177, -2.84264001,\n",
        "         0.63410389, -3.38430242, -2.16836076,  0.78456835,  3.83921132]])\n",
        "```\n",
        "\n",
        "\n",
        "5. (A1.5): graficare il plot del punto A1.3 colorando i punti con l'indice di cluster fornito dal modello GMM, graficando nello stesso plot i punti corrispondenti agli eventi A e B.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "---\n",
        "\n",
        "**Problema A2**\n",
        "\n",
        "Viene fornito il dataset in formato numpy: *dataset_2_AI_24.6.2024.npy*, contenente 400 immagini in scala di grigio di dimensione $(64,64)$ pixels.\n",
        "\n",
        "Per leggere il dataset utilizzare il codice:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "data=np.load('dataset_2_AI_24.6.2024.npy')\n",
        "```\n",
        "\n",
        "1. (A2.1): applicare una riduzione dimensionale 2D basata su PCA e calcolare la varianza spiegata delle due componenti\n",
        "2. (A2.2): graficare lo spazio latente PCA 2D del dataset\n",
        "3. (A2.3): allenare un autoencoder basato su una rete feed-forward shallow (un solo layer nascosto per l'encoder e uno solo per il decoder) con layer lineari, senza parametri di bias e con attivazioni lineari, con rappresentazione latente di dimensione 2, usando MSE come funzione di costo;\n",
        "4. (A2.4): graficare lo spazio latente 2D e confrontare con quanto ottenuto al punto A2.2, commentando il risultato ottenuto.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "---\n",
        "\n",
        "**Problema B1**\n",
        "\n",
        "5. (B1.1): leggere il dataset MNIST da *openml *e graficare 3 immagini scelte in modo random dal campione;\n",
        "6. (B1.2): allenare un modello CNN rispetto al task di classificazione del campione MNIST;\n",
        "7. (B1.3): graficare le *traiettorie di apprendimento della rete*:\n",
        "-  ad ogni epoca di training salvare in un opportuno vettore numpy il valore di tutti i pesi dell'ultimo layer convoluzionale della CNN:\n",
        "\n",
        "```\n",
        "# Suggerimento per accedere al valore dei pesi di un dato layer convoluzionale di un modello DNN \"model\":\n",
        "# se nel modello il layer convoluzionale di interesse è stato per esempio definito dalla istanza:\n",
        "self.conv3 = nn.Conv2d(...)\n",
        "# allora è possibile ottenere il valore corrente dei pesi associati a quel layer tramite l'istruzione:\n",
        "model.conv3.weight.flatten().detach().numpy()\n",
        "```\n",
        "\n",
        "> NOTA: bisogna scrivere il codice in modo da ottenere alla fine dell'allenamento un vettore numpy di dimensione *(numero epoche, numero parametri dell'ultimo layer convoluzionale)*\n",
        "\n",
        "- terminato l'addestramento applicare una PCA 2D al vettore dei pesi per ogni epoca, e graficare lo scatter plot di *pca_0 vs pca_1*, colorando ciascun punto in accordo all'indice di epoca.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "---\n",
        "\n",
        "**Problema B2**\n",
        "\n",
        "Viene fornito un dataset costituito da 500 coppie di punti $(x_{obs}, y_{obs})$, estratti in accordo ad una relazione funzionale 1D: $y=f(x)$ + noise:\n",
        "\n",
        "\n",
        "```\n",
        "# Funzione 1D fornita\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data\n",
        "x_obs = np.hstack([np.linspace(-0.2, 0.2, 500), np.linspace(0.6, 1, 500)])\n",
        "noise = 0.02 * np.random.randn(x_obs.shape[0])\n",
        "y_obs = x_obs + 0.3 * np.sin(2 * np.pi * (x_obs + noise)) + 0.3 * np.sin(4 * np.pi * (x_obs + noise)) + noise\n",
        "\n",
        "# Set plot limits and labels\n",
        "xlims = [-0.5, 1.5]\n",
        "ylims = [-1.5, 2.5]\n",
        "\n",
        "# True values\n",
        "x_true = np.linspace(-0.5, 1.5, 1000)\n",
        "y_true = x_true + 0.3 * np.sin(2 * np.pi * x_true) + 0.3 * np.sin(4 * np.pi * x_true)\n",
        "\n",
        "# test set\n",
        "x_test = torch.linspace(xlims[0], xlims[1], 3000)\n",
        "\n",
        "# Create plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(x_true, y_true, 'b-', linewidth=3, label=\"True function\")\n",
        "ax.plot(x_obs, y_obs, 'ko', markersize=4, label=\"Observations\")\n",
        "ax.set_xlim(xlims)\n",
        "ax.set_ylim(ylims)\n",
        "ax.set_xlabel(\"X\", fontsize=30)\n",
        "ax.set_ylabel(\"Y\", fontsize=30)\n",
        "ax.legend(loc=4, fontsize=15, frameon=False)\n",
        "\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "5. (B2.1): implementare una architettura MLP per il task di regressione: *predire y_obs dato x_obs*;\n",
        "6. (B2.2): allenare 5 modelli della stessa architettura B2.1, utilizzando lo  stesso dataset, ma con inizalizzazione random dei pesi di ogni modello;\n",
        "7. (B2.3): sullo stesso plot graficare i valori \"true\" della funzione $y=f(x)$,\n",
        "i punti del dataset di training $(x_{obs}, y_{obs})$, e il valore medio della predizione di $y$ ottenuto dalle 5 versioni del modello allenate nel punto B2.2, insieme alla banda di incertezza a $\\pm 3\\sigma$ intorno a tale predizione media.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto."
      ],
      "metadata": {
        "id": "IjeivMlvZdhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "lH5VX7IPtGVb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "\n",
        "images, labels = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False, parser=\"pandas\")\n",
        "labels = labels.astype(int) # converte le label in int"
      ],
      "metadata": {
        "id": "Gog0PCCgoTWO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(5, 4))\n",
        "for i in range(3):\n",
        "  ax= figure.add_subplot(1,3,i+1)\n",
        "  idx=np.random.randint(images.shape[0])\n",
        "  ax.imshow(images[idx].reshape(28, 28), cmap='gray')\n",
        "  ax.set_title(labels[idx])\n",
        "  ax.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "cnhNKiMasjJk",
        "outputId": "f65b4a29-6cfe-4bd2-d229-f7c88e3a431c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAACcCAYAAACz1uZ6AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAADOFJREFUeJzt3X9MVfUfx/H39cdIs1YgmdkPnU4q8J9+0JyasorhLKfOtlpFP7RfGmS1kSm0ZtJqltPa1KytraauldIGmbnaEtwCyUaMmeUcaCGZ4NrQGRDw/eP73Vffb/BebvcN58J9Pv57wb33vJWz8+acN59zQt3d3d0CAICjYUEXAAAYemguAAB3NBcAgDuaCwDAHc0FAOCO5gIAcEdzAQC4o7kAANzRXAAA7mguAAB3NJcLFBcXSygUkoyMjKBLQRw5ePCg5OTkyOWXXy6XXXaZZGdnS01NTdBlIU5xHPmvEPcW+6/ff/9d0tLSJBQKycSJE6Wuri7okhAHfvzxR5kxY4Zcd9118vTTT0tXV5ds2rRJTp8+LQcOHJC0tLSgS0Qc4ThyHs3lfx544AE5deqUdHZ2SnNzc0LvFDhv3rx58v3338uRI0ckJSVFRESamppk6tSpkp2dLTt37gy4QsQTjiPncVlMRMrLy+Xzzz+XDRs2BF0K4kxFRYXcfffd/28sIiLjx4+X2bNnS1lZmZw5cybA6hBPOI5oCd9cOjs7JS8vT5YuXSrTpk0LuhzEmba2Nhk1alSPr48ePVra29sT+jdTnMdxpKcRQRcQtC1btsixY8fkm2++CboUxKG0tDSprKyUzs5OGT58uIiItLe3S1VVlYiINDY2Blke4gTHkZ4S+sylpaVFXn31VSkqKpLU1NSgy0EcWrZsmfz666+yZMkSOXTokNTV1Ulubq40NTWJiMi5c+cCrhBB4zjSu4RuLoWFhZKcnCx5eXlBl4I49cwzz8iqVatk+/btkp6eLtOmTZOjR49KQUGBiIiMGTMm4AoRNI4jvUvY5nLkyBHZunWr5Ofny4kTJ6ShoUEaGhrk77//lo6ODmloaJDTp08HXSbiQHFxsZw8eVIqKiqktrZWqqurpaurS0REpk6dGnB1CBLHkYtL2D9F/u677yQrKyvsa55//nn+8gO9yszMlKamJjl27JgMG5awv6MlPI4jF5ewA/2MjAwpKSnp8fXCwkJpbW2VjRs3yuTJkwOoDPHu008/lerqann77bdpLAmO48jFJeyZy8XMmTMn4Rc/4bzy8nJZs2aNZGdnS0pKilRWVspHH30k99xzj5SWlsqIEQn7+xnC4DiSwGcuQF9MmDBBhg8fLuvWrZPW1laZNGmSrF27Vl588UUaCxAGZy4AAHdcMAYAuKO5AADc0VwAAO5oLgAAdzQXAIA7mgsAwB3NBQDgrs+rwEKhUH/WgQHSn8ua2EeGBvYRRNKXfYQzFwCAO5oLAMAdzQUA4I7mAgBwR3MBALijuQAA3NFcAADuaC4AAHc0FwCAO5oLAMAdzQUA4I7mAgBwR3MBALijuQAA3NFcAADuaC4AAHc0FwCAO5oLAMAdzQUA4G5E0AXEs6SkJJXXrVsXNv/2229hP++aa65R+fDhwz1ec9NNN6nc2NgYsU4Ag1dmZqbKVVVVKufm5qr8ySef9HtNHjhzAQC4o7kAANzRXAAA7pi5hLFjxw6VFyxYoHJtba3KH374YdjPW758ucojR47s8ZrevgY/N9xwg8pLly5VefXq1Sp3d3er3NLSovLcuXNVPnjwYKwlIsHMmDFDZbvPTZ8+XWVmLgCAhEVzAQC4o7kAANwl9Mxl9OjRKufn56t87733qlxaWqrytm3botpeXl6eyvX19T1e09DQENVnIjoHDhxQOSUlRWV7vdtm+/ovv/xS5Tlz5qjc21omxLeZM2eqvGTJEpU3bNig8k8//RTT9hYtWhTT++MVZy4AAHc0FwCAO5oLAMAdzQUA4C6hB/pFRUUqFxQUqLxnzx6V7UD+3LlzYT9//PjxKo8ZM0blmpqavpSJKNhFkh9//LHKqampKp86dUrl2bNnq2wH8vb9u3fvVrm8vFzl2267TeXjx4/3VjYCdOWVV6q8fv16le3PMD09XWV748lIRo0apXJycnJU7x8sOHMBALijuQAA3NFcAADuEmrm8sYbb6j88ssvq2wXSd5///0qt7e3R7W9t956S+W2tjaVN23aFNXnIbKxY8eqHOmmgI888ojKkRY92hnNBx98oPLmzZvD1sPMJf7YGYqdsVhlZWUxbe+qq65S2T4g0BqsN0PlzAUA4I7mAgBwR3MBALgbUjMXeyPKp556SuWVK1eq/MUXX6j80EMPqRztjMXKyclRuampSeX9+/fH9Pnoyf7MQ6GQynv37g2bo7V161aVt2zZEtPnIf60traqvG/fvgHdnl1vN1hw5gIAcEdzAQC4o7kAANwN6pmL/Xvx7du3q5yVlaWyXcdiZyyR7hUWycSJE1W29xCy617g78Ybb1TZrmspKSlx3d7ChQvDbm/VqlUqX3rppSrbdTbNzc2O1aEv5s+fH/b7v/zyi8qxzlzsA+csexxqbGyMaXtB4cwFAOCO5gIAcEdzAQC4G1Qzl6SkJJXtfZ3sjMXeS+z1119XOdZ1LNbq1atVtutu3nvvPdftoaeff/5Z5ZkzZ7p+/q233qqyXddi19XYmYz9vt0nn3322VhLRJTuuOOOAd3e4sWLB3R7QeHMBQDgjuYCAHBHcwEAuIvbmYudr4iI1NfXq3z11VerXFFRofLGjRtV9p6x2HU28+bNU9neO8x7+4jMrjuJll03s3v3bpXtmgU780lLS4tp+/A3efJklW+55Zawr//rr7+i+vxLLrlEZft8mMceeyzs++1aqKKiIpXtnC5eceYCAHBHcwEAuKO5AADcxe3MZceOHT2+Zmcs9nq6XdNgr38XFxerbO9F9ueff0ZV4/Lly1UeN26cynfeeafKdt1Lb8/OHqzPy44Xds715JNPqjxr1iyV7fNYItm2bZvKu3btUvnhhx9W2c5s7DoXnukz8K6//nqV7YzDSk5OVvnw4cNhXz9y5EiVJ02aFEV1Pet5/PHHVWbmAgBIWDQXAIA7mgsAwF2ou48LAey14ljZ+UN+fr7Ka9as6fGeESP0iOjs2bMqV1VVqWyvr9troS0tLSq/9tprKv/xxx8q2+vjX3/9tcoTJkxQ+cEHH1TZPt89IyNDrJtvvrnH1zzFuu4jHO995N+w9/6y+4R9Vsbtt9+ucqTr6ZGcPHlSZbsOxu5zdvvHjx+Pafsehvo+8uabb6pcUFAQUCW9s+v17HHkxIkTA1lOr/qyj3DmAgBwR3MBALijuQAA3AU2c1mxYoXK77zzTsT32OvZ9vp4Tk6OylOmTFE5Ly9PZftcBfv37Jad8UT6+3iro6NDZbvuRqT//4Z9qF9Pt9avX6+y3e/s/8ejjz6qsl0rlZqaqvIrr7yisp3z2c+3z2uJdp3NQBjq+8jRo0dVjrQOpa2tTeW6ujqV9+7dq/KhQ4dUtvcmKy0tDbu9+fPnq1xWVhb29UFg5gIACATNBQDgjuYCAHAX2Mxl7ty5KmdlZalcWFjY4z39/TyUu+66S2U7s7HPS//nn39U3rlzZ9j82WefxVpizIb69XRr7NixKu/bt09l+7wV+2+w/1+xfn/ZsmUqM3MZeHbmYdeb1dTUqLx27VqVo73/n/382tpalTs7O1WePn26yj/88ENU2xsIzFwAAIGguQAA3NFcAADuAnuey1dffRU2B+Hbb79V2d4Hyl5nfPfdd1V+6aWX+qcw/GvNzc0qp6enq7xw4UKVFy1apLL9mUd6/oqdyyH+3HfffXG1PXsPw3icsfwbnLkAANzRXAAA7mguAAB3gc1cBoPnnnsu7PftOhYMPiUlJWFztDZv3qxyf64ZweCQlJQUdAmB4MwFAOCO5gIAcEdzAQC4Y+ZyAfu888zMTJXtOpjq6up+rwmDSzzcOwvBuuKKK1R+4okngikkYJy5AADc0VwAAO5oLgAAd8xcLpCbm6uyfQ5DUVGRyh0dHf1eEwYXu66FdS6JZ9y4cSpfe+21YV9fX1/fn+UEhjMXAIA7mgsAwB3NBQDgjuYCAHDHQP8CdhBnh7FnzpwZyHIwCA0bpn9f6+rqUplFlrAqKyuDLqFfcOYCAHBHcwEAuKO5AADcMXO5QHp6etjvr1ixQmV7I0vAzljs3G7BggUqv//++/1dEgbYrFmzonr9rl27+qmSYHHmAgBwR3MBALijuQAA3DFzucCUKVNU3rNnj8ovvPDCQJaDQSjSOhcMfZFuRHn27FmVm5ub+7OcwHDmAgBwR3MBALijuQAA3IW6+/g0I+6JNDT058Or2Ed6roVauXKlyosXL1Z5//79/V1S1NhHEElf9hHOXAAA7mguAAB3NBcAgDtmLgmG6+mIhH0EkTBzAQAEguYCAHBHcwEAuKO5AADc0VwAAO5oLgAAdzQXAIC7Pq9zAQCgrzhzAQC4o7kAANzRXAAA7mguAAB3NBcAgDuaCwDAHc0FAOCO5gIAcEdzAQC4+w+PXgHOS8PAqAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=images\n",
        "y=labels\n",
        "print(X.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC6X_UIGtKg0",
        "outputId": "4ae753e9-dffd-4b69-cbd3-5ccecd6621a8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_val.shape,Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBVCh108uIvo",
        "outputId": "cab3c497-0292-4ff9-f48a-10ee772a443d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784) (56000,)\n",
            "(14000, 784) (14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def rete\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Primo blocco convoluzionale\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)  # Output: 32 x 28 x 28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Output dopo pool: 32 x 14 x 14\n",
        "\n",
        "        # Secondo blocco convoluzionale\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)  # Output: 64 x 14 x 14\n",
        "        # Dopo pool: 64 x 7 x 7\n",
        "\n",
        "        # Fully connected\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # Output finale: 10 classi\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + ReLU + MaxPool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + ReLU + MaxPool\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # No softmax qui, lasciamo che lo faccia CrossEntropyLoss\n",
        "        return x"
      ],
      "metadata": {
        "id": "zmwACHcluQyQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CNN()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3nFIHGyvCAn",
        "outputId": "0d76d452-fde0-4d29-f1bb-d21a8b580122"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
            "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Linear-5                  [-1, 128]         401,536\n",
            "            Linear-6                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 421,642\n",
            "Trainable params: 421,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.36\n",
            "Params size (MB): 1.61\n",
            "Estimated Total Size (MB): 1.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=torch.from_numpy(X_train.reshape(-1,28,28)).float()\n",
        "x_val=torch.from_numpy(X_val.reshape(-1,28,28)).float()\n",
        "y_train=torch.from_numpy(Y_train).long() # Change target data type to LongTensor\n",
        "y_val=torch.from_numpy(Y_val).long() # Change target data type to LongTensor\n",
        "\n",
        "train_ds=TensorDataset(x_train,y_train)\n",
        "train_dl=DataLoader(train_ds,batch_size=32,shuffle=True)\n",
        "val_ds=TensorDataset(x_val,y_val)\n",
        "val_dl=DataLoader(val_ds,batch_size=32,shuffle=True)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # Use CrossEntropyLoss for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95) #cambiare LR\n",
        "\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'using device: {device}')\n",
        "\n",
        "num_epochs=20\n",
        "best_val_acc = 0.0\n",
        "#epochs_since_best_val_acc = 0 #BREAK PREMATURO\n",
        "train_curve=[]\n",
        "val_curve=[]\n",
        "#lr_curve=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    tmp_loss = 0\n",
        "\n",
        "    for (data, target) in train_dl:\n",
        "        # Reshape data to have 1 channel\n",
        "        data = data.unsqueeze(1)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tmp_loss += loss.detach().numpy()\n",
        "\n",
        "    #if epoch > 20:\n",
        "     #scheduler.step()\n",
        "\n",
        "    #lr_curve.append(optimizer.param_groups[0]['lr'])\n",
        "    train_curve.append(tmp_loss/len(train_dl))\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, train_loss: {tmp_loss/len(train_dl):.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip3P2PGyvNSm",
        "outputId": "46620b2a-1eac-4dda-b65d-b59b3da1f240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cpu\n",
            "Epoch 1/20, train_loss: 0.185469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=torch.from_numpy(X_train.reshape(-1,28,28)).float()\n",
        "x_val=torch.from_numpy(X_val.reshape(-1,28,28)).float()\n",
        "y_train=torch.from_numpy(Y_train).float()\n",
        "y_val=torch.from_numpy(Y_val).float()\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQ4U8RQv0sO",
        "outputId": "a3b5ad31-2132-4aec-bc33-2322ca8739b3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56000, 28, 28]) torch.Size([56000])\n",
            "torch.Size([14000, 28, 28]) torch.Size([14000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hb_nD7LUv6YX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}